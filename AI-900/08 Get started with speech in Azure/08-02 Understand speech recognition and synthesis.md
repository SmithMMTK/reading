
_speech recognition_ คือการแปลงเสียงพูดให้กลายเป็นข้อมูลที่สามารถประมวลผลได้ โดยส่วนใหญ่มักจะเป็นการถอดเสียงเป็นข้อความ (_transcribing into text_) ซึ่งเสียงพูดอาจมาจากไฟล์เสียงที่บันทึกไว้หรือเสียงสดจากไมโครโฟนก็ได้ ระบบจะวิเคราะห์รูปแบบเสียง (_speech patterns_) เพื่อหาแพตเทิร์นที่สามารถรู้จำได้และจับคู่กับคำพูด

โดยทั่วไปซอฟต์แวร์จะใช้โมเดลหลายตัว เช่น

- _**acoustic model**_ ซึ่งแปลงสัญญาณเสียงเป็น _phonemes_ (เสียงพื้นฐานในภาษา)  
- _**language model**_ ซึ่งแปลง _phonemes_ เป็นคำ โดยใช้ _statistical algorithm_ เพื่อคาดเดาคำที่น่าจะเป็นไปได้มากที่สุดจากเสียงที่ได้ยิน

คำพูดที่รู้จำได้จะถูกแปลงเป็นข้อความ (_text_) ที่สามารถนำไปใช้ในงานต่าง ๆ ได้ เช่น

- _สร้างคำบรรยาย_ (_closed captions_) ให้กับวิดีโอ  
- _ถอดบทสนทนา_ จากการโทรหรือประชุม  
- _จดบันทึกอัตโนมัติ_ (_automated note dictation_)  
- _เข้าใจสิ่งที่ผู้ใช้ต้องการ_ เพื่อนำไปประมวลผลต่อ

ส่วน _speech synthesis_ คือกระบวนการสร้างเสียงพูดจากข้อมูล โดยทั่วไปคือการแปลงข้อความให้กลายเป็นเสียง (_text to speech_) ซึ่งต้องใช้ข้อมูลหลัก 2 อย่างคือ

- _ข้อความที่ต้องการให้พูด_  
- _เสียงพูดที่ต้องการใช้_ (เช่น เพศ ความเร็ว โทนเสียง)

เพื่อสังเคราะห์เสียง ระบบจะ _tokenize_ ข้อความเพื่อแยกคำ จากนั้นจับคู่คำกับเสียงที่ตรงตามเสียงในภาษา (_phonetic sounds_) แล้วแยกออกเป็นหน่วยเสียงที่เหมาะสม (_prosodic units_ เช่น วลีหรือประโยค) เพื่อสร้าง _phonemes_ ที่จะนำไปแปลงเป็นเสียงพูดต่อไป โดยสามารถปรับเสียงพูดให้มีความเร็ว น้ำเสียง และระดับเสียงได้ตามต้องการ

การสังเคราะห์เสียงสามารถนำไปใช้ได้หลายรูปแบบ เช่น

- ตอบกลับผู้ใช้ด้วยเสียงพูด (_spoken responses_)  
- สร้างเมนูเสียงในระบบโทรศัพท์  
- อ่านอีเมลหรือข้อความออกเสียงในสถานการณ์ที่ต้องใช้แบบ _hands-free_  
- ประกาศในที่สาธารณะ เช่น สถานีรถไฟหรือสนามบิน
