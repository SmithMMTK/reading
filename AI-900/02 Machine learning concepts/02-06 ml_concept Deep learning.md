# Deep Learning

*Deep learning* เป็นรูปแบบขั้นสูงของ *machine learning*  
ซึ่งพยายามจำลองกระบวนการเรียนรู้ของสมองมนุษย์

หัวใจหลักของ deep learning คือการสร้าง *artificial neural network*  
ซึ่งเลียนแบบการทำงานของ *neuron* ในสมอง  
โดยใช้ฟังก์ชันทางคณิตศาสตร์แทนกระแสสัญญาณไฟฟ้า-เคมีใน neuron จริง

| Biological neural network                                                                                                                                                                                                                                                           | Artificial neural network                                                                                                                                                                                                                                                                                                                                 |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ![Diagram of a natural neural network.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-machine-learning/media/biological-neural-network.png)                                                                                                                   | ![Diagram of an artificial neural network.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-machine-learning/media/artificial-neural-network.png)                                                                                                                                                                                     |
| ในสมองของมนุษย์ *neurons* จะตอบสนองต่อสิ่งกระตุ้นทางไฟฟ้า-เคมี (*electrochemical stimuli*)  เมื่อ neuron ถูกกระตุ้นถึงระดับหนึ่ง มันจะ "ยิงสัญญาณ" (*fire*) ออกไป<br><br>สัญญาณนี้จะถูกส่งต่อไปยัง *neuron* อื่น ๆ ที่เชื่อมต่อกัน  เกิดเป็นเครือข่ายของการประมวลผลที่ซับซ้อนในสมอง | ใน *artificial neural network* แต่ละ *neuron* คือฟังก์ชันทางคณิตศาสตร์   ซึ่งรับค่า *input* (_x_) และ *weight* (_w_) แล้วคำนวณผลรวมแบบถ่วงน้ำหนัก ฟังก์ชันของ neuron จะถูก "ห่อ" ด้วย *activation function*  ซึ่งมีหน้าที่ตัดสินใจว่า neuron ควรส่งสัญญาณต่อไปหรือไม่<br> <br>ค่าผลลัพธ์สุดท้าย (_a_) คือ output ที่จะส่งต่อไปยัง neuron ถัดไปในเครือข่าย |
## Deep Neural Networks (DNNs)

*Artificial neural networks* ประกอบด้วยหลายชั้นของ neuron  
ซึ่งโดยโครงสร้างแล้วเป็นการซ้อนกันของฟังก์ชันหลายชั้นอย่างลึก  
จึงเรียกเทคนิคนี้ว่า **deep learning** และโมเดลที่ได้เรียกว่า **deep neural networks (DNNs)**

DNNs สามารถนำไปใช้กับหลายปัญหาใน machine learning เช่น:

- *Regression*  
- *Classification*  
- *Natural Language Processing (NLP)*  
- *Computer Vision*

กระบวนการเรียนรู้ของ DNN เหมือนกับเทคนิค machine learning อื่น ๆ คือ  
การฝึกฟังก์ชันให้เรียนรู้จากข้อมูล training เพื่อนำไปทำนายค่า label (_y_) จาก features (_x_)

ในโมเดล deep learning:  
- ฟังก์ชัน f(x) คือฟังก์ชันซ้อนกันหลายชั้น  
- แต่ละชั้นจะประมวลผล _x_ ด้วยน้ำหนัก _w_ และฟังก์ชันที่เฉพาะเจาะจงของชั้นนั้น

กระบวนการฝึกใช้วิธี:

1. ป้อนค่าของ feature (_x_) ผ่านเลเยอร์ต่าง ๆ เพื่อคำนวณค่าทำนาย (_ŷ_)  
2. เปรียบเทียบ _ŷ_ กับค่าจริง (_y_) เพื่อวัดความคลาดเคลื่อน (เรียกว่า *loss*)  
3. ปรับค่า *weight (w)* เพื่อให้ loss ลดลง

กระบวนการนี้ทำซ้ำหลายรอบ (iterative) จนได้ชุด weight ที่ทำให้โมเดลทำนายได้แม่นที่สุด  
ชุด weight สุดท้ายนี้คือผลลัพธ์ของการฝึกโมเดล

## Example – Using Deep Learning for Classification

เพื่อให้เข้าใจการทำงานของ *deep neural network (DNN)* ได้ชัดเจนยิ่งขึ้น  
ลองพิจารณาตัวอย่างที่ใช้ DNN สำหรับสร้างโมเดล *classification*  
เพื่อจำแนกสายพันธุ์ของเพนกวิน

![Diagram of a neural network used to classify a penguin species.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-machine-learning/media/deep-classification.png)

ในตัวอย่างนี้ ข้อมูล feature (_x_) ประกอบด้วยการวัดค่าต่าง ๆ ของเพนกวิน ได้แก่:

- ความยาวของจะงอยปาก (bill length)  
- ความลึกของจะงอยปาก (bill depth)  
- ความยาวของครีบ (flipper length)  
- น้ำหนักตัว (body mass)

ดังนั้น _x_ จึงเป็นเวกเตอร์ของ 4 ค่า:  
**x = [x₁, x₂, x₃, x₄]**

ส่วน label (_y_) ที่เราต้องการทำนาย คือ *สายพันธุ์ของเพนกวิน*  
โดยมีอยู่ 3 สายพันธุ์ที่เป็นไปได้:

- Adelie  
- Gentoo  
- Chinstrap

นี่คือตัวอย่างของ *classification problem* ซึ่งโมเดลจะต้องทำนายว่าข้อมูลตัวอย่างควรอยู่ในคลาสใด โมเดล classification ทำงานโดยให้ผลลัพธ์เป็นเวกเตอร์ของ *ความน่าจะเป็น*  ของแต่ละคลาส เช่น:  
**y = [P(y = 0 | x), P(y = 1 | x), P(y = 2 | x)]**

### Example - Using deep learning for classification

1. **ป้อนเวกเตอร์ feature เข้าชั้น input ของ neural network**  
   โดยในตัวอย่างนี้ใช้ข้อมูล:  
   **x = [37.3, 16.8, 19.2, 30.0]**  
   ซึ่งประกอบด้วยค่า: ความยาวจะงอยปาก, ความลึกจะงอยปาก, ความยาวครีบ, และน้ำหนัก

2. **ในเลเยอร์แรก** แต่ละ neuron จะคำนวณผลรวมแบบถ่วงน้ำหนัก  
   (x คูณกับ weight แล้วบวก bias)  
   จากนั้นส่งผ่าน *activation function* เพื่อตัดสินว่าจะส่งต่อข้อมูลต่อหรือไม่

3. **แต่ละ neuron ในชั้นหนึ่ง เชื่อมต่อกับ neuron ทุกตัวในชั้นถัดไป**  
   โครงสร้างแบบนี้เรียกว่า *fully connected*  
   ค่าที่ได้จะถูกส่งผ่านจากชั้นหนึ่งไปยังอีกชั้น จนถึง *output layer*

4. **ชั้น output** จะให้ผลลัพธ์เป็นเวกเตอร์ของความน่าจะเป็นของแต่ละคลาส  
   โดยใช้ฟังก์ชันเช่น *softmax* เพื่อแปลงค่าให้รวมกันเป็น 1.0  
   ตัวอย่างผลลัพธ์:  
   **[0.2, 0.7, 0.1]**

5. **ผลลัพธ์นี้แสดงความน่าจะเป็นของคลาส 0, 1 และ 2 ตามลำดับ**  
   ค่า 0.7 สูงที่สุด → โมเดลจึงทำนายว่าเพนกวินตัวนี้คือ *คลาส 1 (Gentoo)*

### How Does a Neural Network Learn?

*Weights* คือหัวใจสำคัญของการเรียนรู้ใน *neural network*  
ระหว่างการฝึก โมเดลจะเรียนรู้ค่าของ weight ที่ทำให้การทำนายแม่นยำที่สุด

![Diagram of a neural network being trained, evaluated, and optimized.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-machine-learning/media/neural-network-training.png)

1. **เริ่มต้นด้วยการเตรียมชุดข้อมูล training และ validation**  
   จากนั้นป้อนค่าของ features (_x_) เข้า *input layer* ของเครือข่าย

2. **neurons ในแต่ละชั้นคำนวณค่าจาก features โดยใช้ weight**  
   ซึ่งในช่วงแรก weight จะถูกกำหนดแบบสุ่ม

3. **output layer** จะให้เวกเตอร์ของค่าทำนาย (_ŷ_)  
   เช่น สำหรับการทำนายสายพันธุ์เพนกวิน:  
   ŷ = [0.3, 0.1, 0.6]

4. **loss function** ถูกใช้เพื่อเปรียบเทียบระหว่าง ŷ และ y ที่รู้จริง  
   เช่น ถ้า y ที่ถูกต้องคือ Chinstrap:  
   y = [0.0, 0.0, 1.0]  
   ความแตกต่างคือ: [0.3, 0.1, 0.4]  
   ระบบจะคำนวณ *loss* โดยรวมค่าความคลาดเคลื่อนจากหลาย ๆ ตัวอย่างเข้าเป็นค่าตัวเลขเดียว

5. **optimization function** จะวิเคราะห์ว่าค่า weight แต่ละตัวส่งผลต่อ loss อย่างไร  
   แล้วคำนวณการปรับค่าที่จะช่วยลด loss  
   โดยปกติจะใช้เทคนิคที่เรียกว่า *gradient descent* เพื่อหาทิศทางและขนาดของการปรับค่า

6. **การเปลี่ยนแปลง weight ถูกส่งย้อนกลับผ่านเครือข่าย**  
   เรียกว่า *backpropagation* โดยจะอัปเดต weight ในแต่ละเลเยอร์ด้วยค่าที่ได้

7. **ทำซ้ำกระบวนการทั้งหมดหลายรอบ (เรียกว่า epochs)**  
   จนกว่า loss จะลดลงและโมเดลสามารถทำนายได้อย่างแม่นยำเพียงพอ

### Efficient Training with Batches and GPUs

แม้จะเข้าใจง่ายกว่าหากคิดว่าข้อมูลแต่ละกรณี (_case_) ถูกส่งผ่านเครือข่ายทีละรายการ  
แต่ในความเป็นจริง ข้อมูลจะถูกจัดเป็น *batch* แล้วประมวลผลเป็น *matrix* ด้วยการคำนวณเชิงพีชคณิตเชิงเส้น (*linear algebra*)

กระบวนการนี้ใช้เวกเตอร์และเมทริกซ์จำนวนมาก  
เช่น การคูณ matrix ของ features กับ matrix ของ weights ในแต่ละเลเยอร์ของเครือข่าย  
จึงต้องอาศัยการประมวลผลที่มีประสิทธิภาพสูง

ด้วยเหตุนี้ การฝึกโมเดล *neural network* มักจะดำเนินการบน *GPU*  
ซึ่งได้รับการออกแบบมาโดยเฉพาะสำหรับการจัดการเวกเตอร์และเมทริกซ์จำนวนมากพร้อมกัน  
ทำให้สามารถฝึกโมเดลได้เร็วและมีประสิทธิภาพมากกว่าการใช้ CPU ทั่วไป