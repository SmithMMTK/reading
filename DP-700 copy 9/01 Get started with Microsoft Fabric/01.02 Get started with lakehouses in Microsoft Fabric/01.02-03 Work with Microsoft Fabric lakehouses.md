
## Create and explore a lakehouse

เมื่อคุณสร้าง _lakehouse_ ใหม่ใน Microsoft Fabric ระบบจะสร้าง 3 รายการข้อมูลให้อัตโนมัติใน _workspace_

- รายการแรกคือ **lakehouse** ซึ่งภายในจะมี _shortcuts_, โฟลเดอร์, ไฟล์ และ _tables_ ที่ใช้เก็บและจัดการข้อมูลดิบหรือข้อมูลที่ถูกแปลงแล้ว
- รายการที่สองคือ **Semantic model (default)** ซึ่งเป็นแบบจำลองข้อมูลที่ช่วยให้ผู้พัฒนา _Power BI reports_ เข้าถึงข้อมูลได้ง่าย โดยไม่ต้องเขียนโค้ดซับซ้อน
- รายการที่สามคือ **SQL analytics endpoint** ที่เปิดให้เข้าถึงข้อมูลแบบอ่านอย่างเดียวผ่าน _SQL_ เหมาะสำหรับใช้ _query_ ข้อมูลด้วยภาษา SQL เพื่อการวิเคราะห์หรือการสร้างรายงานเพิ่มเติม

![Screenshot of the three Lakehouse items as described.](https://learn.microsoft.com/en-us/training/wwl/get-started-lakehouses/media/lakehouse-items.png)

คุณสามารถทำงานกับข้อมูลใน _lakehouse_ ได้ 2 โหมดหลัก:

- โหมด **lakehouse** ช่วยให้คุณสามารถเพิ่มหรือจัดการกับ _tables_, _files_, และ _folders_ ภายใน _lakehouse_ ได้โดยตรง เหมาะกับการ _ingest_, _transform_, และ _organize_ ข้อมูลแบบยืดหยุ่น
- โหมด **SQL analytics endpoint** ช่วยให้คุณสามารถใช้ _SQL_ เพื่อ _query_ ข้อมูลจาก _tables_ และจัดการกับ _relational semantic model_ ได้ โหมดนี้เหมาะสำหรับผู้ที่ถนัด _SQL_ และต้องการวิเคราะห์ข้อมูลในเชิงโครงสร้าง (_structured analysis_)

![Screenshot of the two lakehouse Explorer modes.](https://learn.microsoft.com/en-us/training/wwl/get-started-lakehouses/media/explorer-modes.png)

## Ingest data into a lakehouse

การ _ingest_ ข้อมูลเข้าสู่ _lakehouse_ คือขั้นตอนแรกของกระบวนการ _ETL_ ซึ่งสามารถทำได้หลายวิธี ได้แก่

- **Upload**: อัปโหลดไฟล์จากเครื่องของคุณเข้าสู่ _lakehouse_ โดยตรง
- **Dataflows Gen2**: ใช้ Power Query เพื่อ _import_ และ _transform_ ข้อมูลจากแหล่งต่าง ๆ
- **Notebooks**: ใช้ _Apache Spark_ เพื่อ _ingest_, _transform_, และ _load_ ข้อมูลแบบเขียนโค้ดได้ยืดหยุ่น
- **Data Factory pipelines**: ใช้ _Copy data activity_ เพื่อดึงข้อมูลจากแหล่งข้อมูลอื่นเข้าสู่ _lakehouse_

ข้อมูลที่นำเข้าเหล่านี้สามารถโหลดเก็บไว้ในรูปแบบ _files_ หรือ _tables_ ก็ได้

ควรพิจารณารูปแบบการโหลดข้อมูล (_data loading pattern_) เพื่อเลือกแนวทางที่เหมาะสม เช่น ถ้าต้องการจัดเก็บข้อมูลดิบ (_raw data_) ก่อนการประมวลผล อาจเลือกโหลดเป็น _files_ ก่อน แล้วจึงแปลงเป็น _tables_ หรืออาจใช้ _staging tables_ เพื่อรองรับการจัดการข้อมูลระหว่างทางก็ได้

**Spark job definitions** สามารถใช้เพื่อส่งงานแบบ _batch_ หรือ _streaming_ ไปยัง _Spark clusters_ ได้ โดยคุณสามารถอัปโหลดไฟล์ไบนารีที่ได้จากการ _compile_ โค้ดของภาษาโปรแกรมต่าง ๆ (เช่น ไฟล์ _.jar_ จาก Java) เพื่อใช้ประมวลผลข้อมูลที่อยู่ใน _lakehouse_

นอกจากไฟล์ไบนารีหลักแล้ว คุณยังสามารถปรับแต่งการทำงานของ _job_ ได้เพิ่มเติมด้วยการอัปโหลด _libraries_ เพิ่มเติม หรือใส่ _command line arguments_ ตามต้องการ เพื่อควบคุมพฤติกรรมของงานได้อย่างยืดหยุ่น

หากคุณต้องการจัดการกับข้อมูลจำนวนมากหรือมี _transformation logic_ ที่ซับซ้อน การใช้ _Spark job definitions_ จะช่วยให้การประมวลผลเป็นระบบและมี _performance_ ที่ดีในระดับองค์กร

_ดูรายละเอียดเพิ่มเติม_ ได้ที่ [Create an Apache Spark job definition](https://learn.microsoft.com/en-us/fabric/data-engineering/create-spark-job-definition)

## Access data using shortcuts

อีกวิธีหนึ่งในการเข้าถึงและใช้งานข้อมูลใน _Fabric_ คือการใช้ _shortcuts_ ซึ่งช่วยให้คุณเชื่อมต่อข้อมูลเข้ากับ _lakehouse_ ได้โดยที่ข้อมูลยังคงเก็บอยู่ใน _external storage_

การใช้ _shortcuts_ มีประโยชน์อย่างมากเมื่อคุณต้องดึงข้อมูลจาก _storage account_ อื่น หรือแม้แต่จาก _cloud provider_ คนละราย ภายใน _lakehouse_ คุณสามารถสร้าง _shortcuts_ ที่ชี้ไปยังแหล่งข้อมูลภายนอก เช่น _data warehouses_, _KQL databases_, หรือแม้แต่ _lakehouses_ อื่น ๆ ได้

สิทธิ์การเข้าถึง (_permissions_) และข้อมูลประจำตัว (_credentials_) ของแหล่งข้อมูลต้นทางจะถูกจัดการโดย _OneLake_ โดยอัตโนมัติ และเมื่อมีการเข้าถึงข้อมูลผ่าน _shortcut_ ไปยังที่ตั้งอื่นใน _OneLake_ ระบบจะใช้ตัวตนของผู้ใช้งาน (_calling user_) ในการตรวจสอบสิทธิ์ หากผู้ใช้ไม่มีสิทธิ์ที่ตำแหน่งเป้าหมาย ก็จะไม่สามารถอ่านข้อมูลได้

_shortcuts_ สามารถสร้างได้ทั้งใน _lakehouse_ และ _KQL database_ และจะปรากฏในระบบเหมือนเป็นโฟลเดอร์หนึ่งภายใน _lake_ ซึ่งช่วยให้เครื่องมืออย่าง _Spark_, _SQL_, _Real-Time Intelligence_, และ _Analysis Services_ สามารถใช้งานข้อมูลผ่าน _shortcuts_ ได้

_ดูรายละเอียดเพิ่มเติม_ ได้ที่ [OneLake shortcuts documentation](https://learn.microsoft.com/en-us/fabric/onelake/onelake-shortcuts)

---
