
แพลตฟอร์ม _unified data analytics_ ของ Microsoft Fabric ช่วยให้ผู้เชี่ยวชาญด้านข้อมูลทำงานร่วมกันได้ง่ายขึ้น Fabric ส่งเสริมการทำงานร่วมกันระหว่างทีม โดยขจัด _data silos_ และลดความจำเป็นในการใช้หลายระบบ ทำให้การวิเคราะห์ข้อมูลมีประสิทธิภาพและต่อเนื่องมากขึ้น

## Traditional roles and challenges

ในกระบวนการพัฒนา _analytics_ แบบดั้งเดิม ทีมงานด้านข้อมูลมักประสบกับความท้าทายหลายอย่าง เนื่องจากการแบ่งหน้าที่และขั้นตอนการทำงานที่แยกจากกัน

_data engineers_ ทำหน้าที่จัดเตรียมและปรับแต่งข้อมูลให้กับ _data analysts_ ซึ่งนำข้อมูลนั้นไปใช้สร้างรายงานธุรกิจ ขั้นตอนนี้ต้องประสานงานกันหลายรอบ จึงมักเกิดความล่าช้าและความเข้าใจผิด

_data analysts_ มักต้องแปลงข้อมูลเพิ่มเติมในขั้นตอนปลายทาง (_downstream_) ก่อนจะสามารถสร้างรายงาน Power BI ได้ ซึ่งกินเวลาและมักขาดบริบทสำคัญ ทำให้ยากต่อการเชื่อมโยงกับข้อมูลต้นทาง

_data scientists_ เจออุปสรรคในการนำเทคนิค _data science_ แบบเนทีฟมาใช้งานร่วมกับระบบที่มีอยู่ ซึ่งมักมีความซับซ้อน และทำให้ยากต่อการสร้าง _insights_ ที่มีประสิทธิภาพ

## Evolution of collaborative workflows

Microsoft Fabric ช่วยลดความซับซ้อนของกระบวนการพัฒนา _analytics_ โดยการรวมเครื่องมือต่าง ๆ ไว้ในแพลตฟอร์มแบบ _SaaS_ ทำให้บทบาทต่าง ๆ สามารถทำงานร่วมกันได้อย่างมีประสิทธิภาพ โดยไม่ซ้ำซ้อน

**_data engineers_** สามารถ _ingest_, _transform_ และ _load_ ข้อมูลลงใน _OneLake_ ได้โดยตรงผ่าน _pipelines_ ซึ่งช่วยให้งานเป็นระบบอัตโนมัติและตั้งเวลาได้ ข้อมูลสามารถจัดเก็บไว้ใน _lakehouses_ ด้วยรูปแบบ _Delta-Parquet_ ที่รองรับการจัดเก็บอย่างมีประสิทธิภาพและมีระบบเวอร์ชัน _notebooks_ ก็สามารถใช้เขียนโค้ดสำหรับการแปลงข้อมูลที่ซับซ้อนได้

**_data analysts_** สามารถแปลงข้อมูลตั้งแต่ต้นทาง (_upstream_) ผ่าน _dataflows_ และเชื่อมต่อกับ _OneLake_ โดยตรงผ่าน _Direct Lake mode_ ซึ่งช่วยลดความจำเป็นในการแปลงข้อมูลภายหลัง (_downstream_) และสร้างรายงานแบบ _interactive_ ได้อย่างมีประสิทธิภาพด้วย Power BI

**_data scientists_** ใช้ _notebooks_ ที่รวมมาในระบบ ซึ่งรองรับ _Python_ และ _Spark_ ในการสร้างและทดสอบโมเดล _machine learning_ พร้อมทั้งจัดเก็บและเข้าถึงข้อมูลใน _lakehouses_ และเชื่อมต่อกับ _Azure Machine Learning_ เพื่อใช้งานและนำโมเดลไปใช้งานจริง (_deploy_)

**_analytics engineers_** ทำหน้าที่เป็นสะพานเชื่อมระหว่าง _data engineering_ และ _data analysis_ โดยจัดการ _data assets_ ภายใน _lakehouses_ เพื่อรักษาคุณภาพข้อมูลและส่งเสริม _self-service analytics_ พวกเขาสามารถสร้าง _semantic models_ ใน Power BI เพื่อจัดระเบียบและนำเสนอข้อมูลได้อย่างชัดเจน

**_low-to-no-code users_** และ **_citizen developers_** สามารถค้นหาชุดข้อมูลที่จัดเตรียมไว้แล้ว (_curated datasets_) ผ่าน _OneLake Hub_ และใช้เทมเพลต Power BI เพื่อสร้างรายงานและแดชบอร์ดได้อย่างรวดเร็ว นอกจากนี้ยังสามารถใช้ _dataflows_ ทำ _ETL_ ง่าย ๆ ได้ด้วยตนเองโดยไม่ต้องพึ่งพา _data engineers_

