
_Lakehouse_ ใน _Fabric_ คือศูนย์รวมของ _files_, _folders_, _tables_ และ _shortcuts_ ที่ทำงานคล้ายกับฐานข้อมูลบน _data lake_ ใช้งานร่วมกับ _Spark engine_ และ _SQL engine_ เพื่อประมวลผล _big data_ และยังรองรับ _ACID transactions_ เมื่อตารางถูกจัดเก็บในรูปแบบ _Delta format_

ประสบการณ์ใช้งาน _data warehouse_ ของ Fabric ช่วยให้คุณเปลี่ยนจากการทำงานแบบ _Lakehouse view_ (เหมาะกับ _data engineering_ และ _Apache Spark_) ไปสู่ประสบการณ์แบบ _SQL_ ตามแบบฉบับคลังข้อมูลดั้งเดิม _Lakehouse_ เปิดให้คุณอ่านตารางและใช้งาน _SQL analytics endpoint_ ขณะที่ _data warehouse_ เปิดให้คุณสามารถปรับแต่งและจัดการข้อมูลได้เต็มที่

ใน _data warehouse experience_ คุณสามารถสร้างโมเดลข้อมูลด้วย _tables_ และ _views_, รันคำสั่ง T-SQL เพื่อสืบค้นข้อมูลทั้งจาก _data warehouse_ และ _Lakehouse_, ใช้ T-SQL เพื่อทำ _DML_ และเผยแพร่ข้อมูลไปยังระบบรายงานเช่น Power BI

เมื่อเข้าใจหลักการออกแบบ _relational data warehouse_ แล้ว มาดูวิธีสร้าง _data warehouse_ กัน

## Describe a data warehouse in Fabric

ใน _Fabric_ คุณสามารถสร้างเลเยอร์เชิงสัมพันธ์ (_relational layer_) บนข้อมูลจริงใน _Lakehouse_ และเปิดให้เครื่องมือวิเคราะห์เข้าถึงข้อมูลนั้นได้โดยตรง สามารถสร้าง _data warehouse_ ได้ผ่าน **Create hub** หรือจากภายใน **workspace** โดยตรง หลังจากสร้าง _warehouse_ เปล่าแล้ว คุณสามารถเพิ่มวัตถุ (_objects_) ต่าง ๆ เข้าไปได้

![Screenshot of the Fabric UI with an arrow pointing to the create hub.](https://learn.microsoft.com/en-us/training/wwl/get-started-data-warehouse/media/create-data-warehouse.png)

เมื่อสร้าง _warehouse_ แล้ว คุณสามารถสร้างตารางผ่าน T-SQL โดยตรงจาก _Fabric UI_

## Ingest data into your data warehouse

มีหลายวิธีในการนำเข้าข้อมูลสู่ _Fabric data warehouse_ ได้แก่:

- _Pipelines_
- _Dataflows_
- _Cross-database querying_
- คำสั่ง `COPY INTO`

หลังจากนำเข้าข้อมูลแล้ว ข้อมูลจะพร้อมสำหรับการวิเคราะห์โดยหลายฝ่ายธุรกิจ และสามารถแชร์หรือสืบค้นแบบข้ามฐานข้อมูลได้

### Create tables

คุณสามารถสร้างตารางใน _data warehouse_ ได้โดยใช้ SQL Server Management Studio (SSMS) หรือ _SQL client_ อื่น ๆ โดยรันคำสั่ง `CREATE TABLE` หรือจะสร้างตารางจาก _Fabric UI_ ก็ได้

สามารถคัดลอกข้อมูลจากภายนอกเข้าตารางใน _data warehouse_ ได้โดยใช้คำสั่ง `COPY INTO` เช่น:

```sql
COPY INTO dbo.Region 
FROM 'https://mystorageaccountxxx.blob.core.windows.net/private/Region.csv' 
WITH ( 
    FILE_TYPE = 'CSV',
    CREDENTIAL = ( 
        IDENTITY = 'Shared Access Signature',
        SECRET = 'xxx'
    ),
    FIRSTROW = 2
)
GO
```


คำสั่ง SQL ด้านล่างนี้ใช้โหลดข้อมูลจากไฟล์ CSV ที่เก็บอยู่ใน Azure Blob Storage เข้าสู่ตารางชื่อ "Region" ภายใน _Fabric data warehouse_

![Screenshot of the SQL query editor with a query open.](https://learn.microsoft.com/en-us/training/wwl/get-started-data-warehouse/media/create-table-manual.png)

### Clone tables

คุณสามารถสร้าง _table clone_ แบบไม่ใช้พื้นที่ซ้ำ (_zero-copy clones_) ได้ภายใน _data warehouse_ โดยสำเนาตารางเหล่านี้จะสร้างจากการคัดลอกเฉพาะ _metadata_ และยังอ้างอิงไฟล์ข้อมูลเดิมใน _OneLake_ อยู่ ซึ่งหมายความว่าข้อมูลจริงที่จัดเก็บในรูปแบบ _parquet files_ จะไม่ถูกทำซ้ำ ช่วยประหยัดต้นทุนพื้นที่จัดเก็บ

[Table clones](https://learn.microsoft.com/en-us/fabric/data-warehouse/clone-table) มีประโยชน์ในหลายกรณี เช่น:

- **Development and testing:** ช่วยให้นักพัฒนาและผู้ทดสอบสามารถสร้างสำเนาตารางในสภาพแวดล้อมที่แยกต่างหาก เพื่อใช้พัฒนา ทดสอบ และตรวจสอบ
- **Data recovery:** หากเกิดความเสียหายกับข้อมูลหรือการปล่อยเวอร์ชันล้มเหลว สามารถใช้ clone เพื่อย้อนกลับไปยังสถานะก่อนหน้าได้
- **Historical reporting:** ใช้สร้างรายงานย้อนหลังที่อิงกับสถานะของข้อมูลในช่วงเวลาสำคัญ

สามารถสร้าง _table clone_ ได้โดยใช้คำสั่ง T-SQL [`CREATE TABLE AS CLONE OF`](https://learn.microsoft.com/en-us/sql/t-sql/statements/create-table-as-clone-of-transact-sql)

ดูตัวอย่างการใช้งานได้จาก [Tutorial: Clone a table using T-SQL in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-warehouse/tutorial-clone-table)

### Table considerations

หลังจากสร้างตารางใน _data warehouse_ แล้ว ควรพิจารณาวิธีการโหลดข้อมูลเข้าไปในตาราง วิธีที่พบบ่อยคือการใช้ _staging tables_ ซึ่งเป็นตารางชั่วคราวสำหรับการทำความสะอาด แปลง และตรวจสอบข้อมูลก่อนจะโหลดเข้าสู่ตารางหลัก

คุณสามารถใช้คำสั่ง T-SQL เพื่อโหลดข้อมูลจากไฟล์เข้าสู่ _staging tables_ ได้ อีกทั้งยังสามารถรวมข้อมูลจากหลายแหล่งไปยังตารางปลายทางเดียวได้ด้วย

โดยทั่วไป การโหลดข้อมูลจะทำแบบ _batch process_ ตามรอบเวลา เช่น รายวัน รายสัปดาห์ หรือรายเดือน โดยควรออกแบบกระบวนการโหลดข้อมูลในลำดับต่อไปนี้:

1. ดึงข้อมูลใหม่เข้าสู่ _data lake_ พร้อมดำเนินการทำความสะอาดเบื้องต้นหากจำเป็น
2. โหลดข้อมูลจากไฟล์เข้าสู่ _staging tables_ ภายใน _data warehouse_
3. โหลดข้อมูล _dimension_ จาก staging โดยอัปเดตแถวเดิมหรือเพิ่มแถวใหม่ และสร้าง _surrogate keys_ ตามต้องการ
4. โหลดข้อมูล _fact_ จาก staging โดยค้นหา _surrogate keys_ ที่สอดคล้องกับ _dimension_ ต่าง ๆ
5. ปรับแต่งหลังโหลด เช่น อัปเดต _indexes_ และ _distribution statistics_

หากคุณมีตารางใน _Lakehouse_ และต้องการสืบค้นจาก _data warehouse_ โดยไม่ต้องคัดลอกข้อมูล ก็สามารถใช้ _cross-database querying_ เพื่อสืบค้นข้อมูลใน _Lakehouse_ ได้โดยตรง

**Important**  
การใช้งานตารางใน _Fabric data warehouse_ ยังมีข้อจำกัดบางประการ ดูรายละเอียดได้ที่ [Tables in data warehousing in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-warehouse/tables)
