_Spark_ เป็นเฟรมเวิร์กสำหรับประมวลผลแบบขนาน (_parallel-processing_) ซึ่งข้อมูลจะถูกจัดเก็บไว้ในโหนดทำงาน (_worker nodes_) หลายเครื่อง

นอกจากนี้ไฟล์ _Parquet_ มีลักษณะเป็นแบบ _immutable_ คือไม่สามารถเขียนทับได้โดยตรง ทุกครั้งที่มีการ _update_ หรือ _delete_ ข้อมูลจะต้องมีการสร้างไฟล์ใหม่ขึ้นมาแทน ส่งผลให้ _Spark_ อาจสร้างไฟล์จำนวนมากที่มีขนาดเล็ก ซึ่งเรียกว่าปัญหา _small file problem_

ปัญหานี้ทำให้การรัน _query_ ที่ต้องอ่านข้อมูลจำนวนมากอาจทำงานช้า หรือถึงขั้นรันไม่สำเร็จเลยก็ได้

## OptimizeWrite function

_OptimizeWrite_ เป็นฟีเจอร์ของ _Delta Lake_ ที่ช่วยลดจำนวนไฟล์ขนาดเล็กโดยตรงในขั้นตอนการเขียนข้อมูล โดยปกติแล้วหากไม่มีฟีเจอร์นี้ การเขียนข้อมูลในแต่ละครั้งจะสร้างไฟล์เล็ก ๆ จำนวนมาก แต่ _OptimizeWrite_ จะรวมข้อมูลให้เขียนออกมาเป็นไฟล์ที่มีขนาดใหญ่ขึ้นและจำนวนน้อยลง

สิ่งนี้ช่วยลดปัญหาเรื่อง _small file problem_ และยังช่วยให้ _performance_ ไม่ลดลงเมื่อทำ _query_ กับข้อมูลจำนวนมาก

![Diagram showing how Optimize Write writes fewer large files.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/optimize-write.png)

ใน _Microsoft Fabric_ ฟีเจอร์ _OptimizeWrite_ จะถูกเปิดใช้งาน (_enabled_) ไว้โดยอัตโนมัติ แต่คุณสามารถเปิดหรือปิดใช้งานฟีเจอร์นี้ได้เองในระดับ _Spark session_

```python
# Disable Optimize Write at the Spark session level
spark.conf.set("spark.microsoft.delta.optimizeWrite.enabled", False)

# Enable Optimize Write at the Spark session level
spark.conf.set("spark.microsoft.delta.optimizeWrite.enabled", True)

print(spark.conf.get("spark.microsoft.delta.optimizeWrite.enabled"))
```

_หมายเหตุ_

_OptimizeWrite_ นอกจากจะตั้งค่าได้ในระดับ _Spark session_ แล้ว ยังสามารถกำหนดใน _Table Properties_ หรือแม้กระทั่งในการสั่ง _write_ แต่ละครั้งแบบเฉพาะเจาะจงก็ได้

การตั้งค่าระดับละเอียดแบบนี้ช่วยให้คุณควบคุมการเขียนข้อมูลได้อย่างเหมาะสมกับบริบทและขนาดของงานในแต่ละกรณี

## Optimize

_Optimize_ เป็นฟีเจอร์สำหรับดูแลรักษาตาราง (_table maintenance_) โดยมีหน้าที่รวมไฟล์ _Parquet_ ขนาดเล็กหลาย ๆ ไฟล์ให้กลายเป็นไฟล์ขนาดใหญ่จำนวนน้อยลง

มักจะใช้หลังจากที่มีการโหลดข้อมูลขนาดใหญ่เข้าไปในตาราง ซึ่งจะให้ผลลัพธ์เช่น:

- มีไฟล์ขนาดใหญ่และจำนวนน้อยลง
- การบีบอัดข้อมูล (_compression_) มีประสิทธิภาพมากขึ้น
- การกระจายข้อมูลไปยังแต่ละโหนดมีความเหมาะสมขึ้น

![Diagram showing how Optimize consolidates Parquet files.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/optimize-command.png)

ใน _Microsoft Fabric_ สามารถรันคำสั่ง _Optimize_ ได้ตามขั้นตอนนี้:

1. ไปที่ _Lakehouse Explorer_ แล้วคลิกเมนู `...` ข้างชื่อ _table_
2. เลือก _Maintenance_
3. คลิก _Run OPTIMIZE command_
4. (ไม่บังคับ) เลือก _Apply V-order_ เพื่อเพิ่มความเร็วในการอ่านข้อมูลใน _Fabric_
5. คลิก _Run now_

### V-Order function

เมื่อคุณรันคำสั่ง _Optimize_ คุณสามารถเลือกเปิดใช้งาน _V-Order_ เพิ่มเติมได้ด้วย ซึ่ง _V-Order_ ถูกออกแบบมาโดยเฉพาะสำหรับไฟล์ _Parquet_ ใน _Fabric_

_V-Order_ ช่วยให้การอ่านข้อมูลเร็วขึ้นระดับเกือบเท่ากับการเข้าถึงข้อมูลในหน่วยความจำ (_in-memory_) และยังช่วยประหยัดต้นทุน โดยลดการใช้ทรัพยากรเครือข่าย, ดิสก์ และ CPU ขณะอ่านข้อมูล

ใน _Microsoft Fabric_ ฟีเจอร์ _V-Order_ จะเปิดใช้งานเป็นค่าเริ่มต้น และถูกนำมาใช้ทันทีเมื่อมีการเขียนข้อมูล แม้จะมีค่าใช้จ่ายเล็กน้อยในด้าน _performance_ (การเขียนจะช้าลงเล็กน้อยประมาณ 15%) แต่จะได้ประโยชน์มากในด้านการอ่านข้อมูลเร็วขึ้นจาก _compute engines_ ต่าง ๆ เช่น _Power BI_, _SQL_, _Spark_ และอื่น ๆ

สำหรับ _Power BI_ และ _SQL engine_ จะใช้เทคโนโลยี _Microsoft Verti-Scan_ ที่ออกแบบมาเพื่อใช้ประโยชน์จาก _V-Order_ ได้เต็มที่ ทำให้การอ่านข้อมูลเร็วขึ้นอย่างมาก ส่วน _Spark_ และเอนจินอื่น ๆ แม้จะไม่ได้ใช้ _Verti-Scan_ แต่ก็ยังได้ประโยชน์จาก _V-Order_ เช่นกัน โดยอาจอ่านข้อมูลได้เร็วขึ้นประมาณ 10% และบางกรณีสูงถึง 50%

_V-Order_ ทำงานโดยการใช้การเรียงลำดับพิเศษ (_special sorting_), การกระจาย _row group_, การเข้ารหัสแบบ _dictionary encoding_ และการบีบอัดข้อมูล (_compression_) บนไฟล์ _Parquet_

_V-Order_ ยังสามารถใช้งานร่วมกับ _Parquet_ ทุกระบบได้ เพราะยังคงเป็นไปตามมาตรฐาน _Parquet_ แบบเปิด 100%

อย่างไรก็ตาม หากคุณมีกรณีที่ต้องเขียนข้อมูลจำนวนมากและอ่านเพียง 1–2 ครั้ง เช่น _staging data store_ การปิด _V-Order_ อาจช่วยลดเวลาในการประมวลผลข้อมูลโดยรวม

คุณสามารถเปิดใช้ _V-Order_ แบบเฉพาะกับแต่ละตารางได้โดยใช้ฟีเจอร์ _Table Maintenance_ และรันคำสั่ง _OPTIMIZE_

![Screen picture of table maintenance with V-order selected](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/table-maintenance-v-order.png)

## Vacuum

คำสั่ง _VACUUM_ ใช้สำหรับลบไฟล์ข้อมูลเก่าที่ไม่จำเป็นแล้วออกจากระบบ

ทุกครั้งที่มีการ _update_ หรือ _delete_ ข้อมูลในตาราง จะมีการสร้างไฟล์ _Parquet_ ใหม่ขึ้นมา และบันทึกการเปลี่ยนแปลงลงใน _transaction log_ ส่วนไฟล์เก่า ๆ จะยังถูกเก็บไว้เพื่อรองรับความสามารถในการ _time travel_ ทำให้ไฟล์ _Parquet_ สะสมมากขึ้นเรื่อย ๆ

คำสั่ง _VACUUM_ จะลบเฉพาะไฟล์ _Parquet_ เก่าที่ไม่ได้ถูกอ้างอิงอยู่ใน _transaction log_ และมีอายุมากกว่าระยะเวลาที่กำหนด (_retention period_) ส่วนไฟล์ _transaction log_ จะยังคงอยู่

เมื่อคุณรัน _VACUUM_ จะไม่สามารถใช้ _time travel_ ย้อนกลับไปก่อนระยะเวลา _retention_ ได้อีก

![Diagram showing how vacuum works.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/how-vacuum-works.png)

การตั้งค่า _retention period_ ควรคำนึงถึงเรื่องต่าง ๆ เช่น:
- ข้อกำหนดด้านการเก็บรักษาข้อมูล (_data retention requirements_)
- ขนาดข้อมูลและต้นทุนการเก็บ (_data size and storage costs_)
- ความถี่ในการเปลี่ยนแปลงข้อมูล (_data change frequency_)
- ข้อกำหนดด้านกฎหมายหรือระเบียบ (_regulatory requirements_)

ค่าเริ่มต้นของ _retention period_ คือ 7 วัน (168 ชั่วโมง) และระบบจะไม่ยอมให้ตั้งระยะเวลาที่สั้นกว่านี้

คุณสามารถรันคำสั่ง _VACUUM_ ได้ทั้งแบบ _ad-hoc_ หรือกำหนดเวลาให้รันเป็นรอบ ๆ ผ่าน _Fabric notebooks_

หากต้องการรัน _VACUUM_ แบบเฉพาะตาราง ให้ทำตามขั้นตอนนี้:

1. ไปที่ _Lakehouse Explorer_ แล้วคลิกเมนู `...` ข้างชื่อ _table_
2. เลือก _Maintenance_
3. คลิก _Run VACUUM command using retention threshold_ และตั้งค่า _retention threshold_
4. คลิก _Run now_

![Screen picture showing the table maintenance options.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/table-maintenance-vacuum.png)

คุณยังสามารถรันคำสั่ง _VACUUM_ ได้โดยตรงผ่าน _SQL_ ใน _notebook_ ด้วยเช่นกัน ตัวอย่าง:

```sql
%%sql
VACUUM lakehouse2.products RETAIN 168 HOURS;
```

คำสั่ง _VACUUM_ จะบันทึกการทำงานไว้ใน _Delta transaction log_ ดังนั้นคุณสามารถตรวจสอบประวัติการรันคำสั่งย้อนหลังได้ด้วยคำสั่ง:

```sql
%%sql
DESCRIBE HISTORY lakehouse2.products;
```

## Partitioning Delta tables

_Delta Lake_ อนุญาตให้คุณจัดระเบียบข้อมูลด้วยการใช้ _partitioning_ ซึ่งอาจช่วยเพิ่ม _performance_ ได้ด้วยการใช้เทคนิคที่เรียกว่า _data skipping_ คือระบบจะข้ามไฟล์หรือพาร์ทิชันที่ไม่เกี่ยวข้องออกไปโดยดูจาก _metadata_ ทำให้ไม่ต้องอ่านข้อมูลทั้งหมด

ลองพิจารณากรณีที่คุณเก็บข้อมูลยอดขายจำนวนมาก คุณสามารถ _partition_ ข้อมูลโดยใช้ปี เช่น แยกเก็บในโฟลเดอร์ชื่อ `"year=2021"`, `"year=2022"` เป็นต้น ถ้าคุณต้องการดูข้อมูลเฉพาะปี 2024 ระบบก็จะข้ามไฟล์ของปีอื่น ๆ ไป ซึ่งช่วยให้การอ่านข้อมูลเร็วขึ้น

แต่ถ้าข้อมูลมีปริมาณน้อย การใช้ _partitioning_ อาจทำให้ประสิทธิภาพแย่ลงได้ เพราะจะสร้างไฟล์จำนวนมากขึ้น และทำให้เกิดปัญหา _small files problem_

ควรใช้ _partitioning_ เมื่อ:
- คุณมีข้อมูลปริมาณมาก
- ตารางสามารถแบ่งออกเป็นพาร์ทิชันขนาดใหญ่เพียงไม่กี่กลุ่มได้

ไม่ควรใช้ _partitioning_ เมื่อ:
- ข้อมูลมีปริมาณน้อย
- คอลัมน์ที่ใช้แบ่งพาร์ทิชันมีค่าที่หลากหลายมาก (_high cardinality_) เพราะจะทำให้เกิดพาร์ทิชันจำนวนมากเกินไป
- การแบ่งพาร์ทิชันนำไปสู่โครงสร้างหลายระดับซับซ้อน

![Diagram showing partitioning by one or more columns.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/partitioning.png)

_partition_ คือรูปแบบการจัดวางข้อมูลแบบตายตัว (_fixed data layout_) ซึ่งจะไม่ปรับเปลี่ยนตามรูปแบบของ _query_ ที่ใช้งานจริง ดังนั้นเมื่อคุณวางแผนจะใช้ _partitioning_ ควรพิจารณาว่าข้อมูลถูกใช้งานอย่างไร และมีความละเอียดระดับไหน (_granularity_)

ตัวอย่างเช่น หากคุณมี _DataFrame_ ที่เก็บข้อมูลสินค้า คุณอาจเลือกแบ่ง _partition_ ตาม _Category_ ของสินค้า เพื่อให้การสืบค้นตามประเภททำได้เร็วขึ้น

```python
df.write.format("delta").partitionBy("Category").saveAsTable("partitioned_products", path="abfs_path/partitioned_products")
```

ใน _Lakehouse Explorer_ คุณจะเห็นว่า _table_ ที่มีการทำ _partitioning_ จะถูกจัดเก็บเป็นโฟลเดอร์ย่อยตามค่าของคอลัมน์ที่ใช้แบ่งพาร์ทิชัน
 
ตัวอย่างเช่น:
- มีโฟลเดอร์หลักชื่อ `"partitioned_products"`
- ภายในมีโฟลเดอร์ย่อยตามแต่ละ _Category_ เช่น `"Category=Bike Racks"`, `"Category=Helmets"` เป็นต้น

![Screen picture of the lakehouse explorer and the product file partitioned by category.](https://learn.microsoft.com/en-us/training/wwl/work-delta-lake-tables-fabric/media/explorer-partitioned-table.png)

เราสามารถสร้าง _partitioned table_ แบบเดียวกันได้โดยใช้ _SQL_ เช่น:

```sql
%%sql
CREATE TABLE partitioned_products (
    ProductID INTEGER,
    ProductName STRING,
    Category STRING,
    ListPrice DOUBLE
)
PARTITIONED BY (Category);
```

