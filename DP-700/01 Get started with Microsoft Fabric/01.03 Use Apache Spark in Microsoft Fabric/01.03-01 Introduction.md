
https://learn.microsoft.com/en-us/training/modules/use-apache-spark-work-files-lakehouse/

_Apache Spark_ เป็นเฟรมเวิร์กแบบ _open source_ สำหรับการประมวลผลข้อมูลขนาดใหญ่ (_large-scale data processing_) แบบขนาน (_parallel processing_) โดยนิยมใช้กันมากในงานที่เกี่ยวกับ _big data_

_Spark_ มีให้ใช้งานในหลายแพลตฟอร์ม เช่น _Azure HDInsight_, _Azure Synapse Analytics_ และ _Microsoft Fabric_

ในบทเรียนนี้ เราเรียนรู้การใช้งาน _Spark_ บน _Microsoft Fabric_ เพื่อทำ _data ingestion_, การประมวลผลข้อมูล (_processing_) และการวิเคราะห์ข้อมูล (_analytics_) ภายใน _lakehouse_

แม้ว่าวิธีและโค้ดหลักที่ใช้ในบทเรียนนี้จะสามารถใช้ได้กับ _Spark_ ทุกเวอร์ชัน แต่จุดเด่นของ _Microsoft Fabric_ คือการรวมเครื่องมือหลากหลายเข้าด้วยกัน และสามารถใช้งาน _Spark_ ควบคู่กับบริการข้อมูลอื่น ๆ ได้ในที่เดียว ช่วยให้การนำ _Spark-based data processing_ เข้าไปอยู่ในโซลูชันวิเคราะห์ข้อมูลทั้งหมดทำได้ง่ายขึ้น

