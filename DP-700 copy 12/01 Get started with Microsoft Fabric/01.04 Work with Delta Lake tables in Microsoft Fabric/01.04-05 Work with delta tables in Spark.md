
คุณสามารถทำงานกับ _delta tables_ (หรือไฟล์ในรูปแบบ _delta format_) เพื่อ _ดึงข้อมูล_ และ _แก้ไขข้อมูล_ ได้หลากหลายวิธี

## Using Spark SQL

วิธีที่พบบ่อยที่สุดในการทำงานกับข้อมูลใน _delta tables_ บน _Spark_ คือการใช้ _Spark SQL_ คุณสามารถฝังคำสั่ง _SQL_ ลงในภาษาอื่น ๆ เช่น _PySpark_ หรือ _Scala_ ได้โดยใช้ไลบรารี spark.sql ตัวอย่างเช่น โค้ดด้านล่างนี้ใช้สำหรับ _เพิ่มแถวข้อมูล_ ลงในตาราง _products_

```python
spark.sql("INSERT INTO products VALUES (1, 'Widget', 'Accessories', 2.99)")
```

อีกวิธีหนึ่งคือ คุณสามารถใช้ `%%sql` magic ในสมุดบันทึกเพื่อเรียกใช้คําสั่ง SQL

```sql
%%sql

UPDATE products
SET ListPrice = 2.49 WHERE ProductId = 1;
```

## Use the Delta API

เมื่อคุณต้องการทํางานกับไฟล์ delta แทนตารางแค็ตตาล็อก อาจง่ายกว่าการใช้ Delta Lake API คุณสามารถสร้างอินสแตนซ์ของ **DeltaTable** จากตําแหน่งโฟลเดอร์ที่ประกอบด้วยไฟล์ในรูปแบบ delta จากนั้นใช้ API เพื่อปรับเปลี่ยนข้อมูลในตาราง

```python
from delta.tables import *
from pyspark.sql.functions import *

# Create a DeltaTable object
delta_path = "Files/mytable"
deltaTable = DeltaTable.forPath(spark, delta_path)

# Update the table (reduce price of accessories by 10%)
deltaTable.update(
    condition = "Category == 'Accessories'",
    set = { "Price": "Price * 0.9" })
```

## Use _time travel_ to work with table versioning

การเปลี่ยนแปลงใด ๆ ที่เกิดขึ้นกับ _delta tables_ จะถูกบันทึกไว้ใน _transaction log_ ของตารางนั้น คุณสามารถใช้ข้อมูลใน _log_ เหล่านี้เพื่อดู _ประวัติการเปลี่ยนแปลง_ ที่เคยเกิดขึ้น และสามารถเรียกคืน _เวอร์ชันเก่า_ ของข้อมูลได้ (_เรียกว่า_ _time travel_)

หากต้องการดูประวัติของตาราง สามารถใช้คำสั่ง _SQL_ ดังนี้:

```sql
%%sql

DESCRIBE HISTORY products
```

ผลลัพธ์จากคำสั่งนี้จะแสดงรายการ _ธุรกรรม_ (_transactions_) ที่ถูกนำมาใช้กับ _table_ ดังตัวอย่างด้านล่าง (บางคอลัมน์ถูกละไว้เพื่อความกระชับ):

| version | timestamp            | operation    | operationParameters                                                          |
| ------- | -------------------- | ------------ | ---------------------------------------------------------------------------- |
| 2       | 2023-04-04T21:46:43Z | UPDATE       | {"predicate":"(ProductId = 1)"}                                              |
| 1       | 2023-04-04T21:42:48Z | WRITE        | {"mode":"Append","partitionBy":"[]"}                                         |
| 0       | 2023-04-04T20:04:23Z | CREATE TABLE | {"isManaged":"true","description":null,"partitionBy":"[]","properties":"{}"} |

หากต้องการดู _ประวัติการเปลี่ยนแปลง_ ของ _external table_ คุณสามารถระบุ _ตำแหน่งโฟลเดอร์_ ที่เก็บไฟล์ _delta format_ แทนที่จะใช้ชื่อ _table_ ได้โดยตรง

```sql
%%sql

DESCRIBE HISTORY 'Files/mytable'
```

คุณสามารถดึงข้อมูลจาก _เวอร์ชันที่ต้องการ_ ของ _delta table_ ได้ โดยการอ่านจากตำแหน่งไฟล์ _delta_ เข้ามาเป็น _dataframe_ พร้อมระบุ _เวอร์ชัน_ ที่ต้องการผ่านพารามิเตอร์ versionAsOf

```python
df = spark.read.format("delta").option("versionAsOf", 0).load(delta_path)
```

อีกทางหนึ่ง คุณสามารถระบุ _timestamp_ เพื่อดึงข้อมูลจากช่วงเวลานั้นได้ โดยใช้พารามิเตอร์ timestampAsOf

```python
df = spark.read.format("delta").option("timestampAsOf", '2022-01-01').load(delta_path)
```

