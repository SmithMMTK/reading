
_Apache Spark_ เป็นเฟรมเวิร์กสำหรับประมวลผลข้อมูลแบบกระจาย (_distributed data processing_) ซึ่งช่วยให้สามารถวิเคราะห์ข้อมูลขนาดใหญ่ (_large-scale data analytics_) ได้อย่างรวดเร็ว โดยทำงานผ่านหลายเครื่องที่เรียกว่า _processing nodes_ ซึ่งใน _Microsoft Fabric_ จะเรียกรวมกันว่า _Spark pool_

พูดง่าย ๆ คือ _Spark_ ใช้แนวคิด “_divide and conquer_” โดยแบ่งงานออกเป็นส่วน ๆ แล้วกระจายไปยังหลายเครื่องเพื่อประมวลผลพร้อมกัน จากนั้นจึงรวบรวมผลลัพธ์กลับมา ซึ่ง _Spark_ จะจัดการกระบวนการเหล่านี้ให้อัตโนมัติ

_Spark_ รองรับการเขียนโค้ดได้หลายภาษา เช่น _Java_, _Scala_ (ภาษาสคริปต์ที่ใช้พื้นฐาน _Java_), _Spark R_, _Spark SQL_ และ _PySpark_ (เวอร์ชันของ _Python_ ที่ออกแบบมาใช้กับ _Spark_ โดยเฉพาะ) ในทางปฏิบัติ งานส่วนใหญ่ของ _data engineering_ และ _analytics_ มักใช้การผสมผสานระหว่าง _PySpark_ และ _Spark SQL_ เป็นหลัก

## Spark pools

_Spark pool_ คือกลุ่มของ _compute nodes_ ซึ่งทำหน้าที่กระจายงานประมวลผลข้อมูล (_data processing tasks_) ออกไปยังแต่ละเครื่อง โครงสร้างทั่วไปของระบบมีลักษณะตามแผนภาพด้านล่าง ซึ่งแสดงให้เห็นว่า _Spark_ แบ่งงานออกเป็นส่วน ๆ และส่งไปยัง _nodes_ หลายตัวเพื่อประมวลผลแบบขนาน (_parallel processing_) จากนั้นจะรวบรวมผลลัพธ์กลับมาโดยอัตโนมัติ

![Diagram of a Spark pool.](https://learn.microsoft.com/en-us/training/wwl/use-apache-spark-work-files-lakehouse/media/spark-pool.png)

As shown in the diagram, a Spark pool contains two kinds of node:

ตามที่แสดงในแผนภาพ _Spark pool_ จะประกอบด้วย _nodes_ สองประเภท:

1. _Head node_ ทำหน้าที่เป็นตัวประสานงาน (_coordinator_) โดยรันโปรแกรมที่เรียกว่า _driver program_ เพื่อควบคุมกระบวนการแบบกระจาย
2. _Worker nodes_ หลายตัวทำหน้าที่ประมวลผลข้อมูลจริงผ่าน _executor processes_

_Spark pool_ ใช้สถาปัตยกรรมแบบกระจาย (_distributed compute architecture_) นี้ในการเข้าถึงและประมวลผลข้อมูลจาก _data store_ ที่รองรับ เช่น _lakehouse_ ที่เก็บอยู่ใน _OneLake_

### Spark pools in Microsoft Fabric

_Microsoft Fabric_ มี _starter pool_ ให้ในแต่ละ _workspace_ เพื่อให้สามารถเริ่มรัน _Spark jobs_ ได้อย่างรวดเร็ว โดยไม่ต้องตั้งค่ามาก

เราสามารถปรับแต่ง _starter pool_ ได้ตามความต้องการ เช่น ปรับขนาดหรือจำนวน _nodes_ ให้เหมาะกับลักษณะงานหรือข้อจำกัดด้านต้นทุน (_cost constraints_)

นอกจากนี้ ยังสามารถสร้าง _Spark pool_ แบบกำหนดเอง (_custom Spark pool_) ได้ โดยเลือกโครงสร้าง _nodes_ ให้เหมาะกับการประมวลผลข้อมูลเฉพาะทาง

_หมายเหตุ_: ความสามารถในการปรับแต่ง _Spark pool_ อาจถูกปิดไว้โดยผู้ดูแลระบบ _Fabric_ ที่ระดับ _Fabric Capacity_  
ดูข้อมูลเพิ่มเติมได้ที่ [Capacity administration settings for Data Engineering and Data Science](https://learn.microsoft.com/en-us/fabric/data-engineering/capacity-settings-overview)

การจัดการ _starter pool_ และการสร้าง _Spark pool_ ใหม่สามารถทำได้ที่ **Admin portal** ของ _workspace settings_ ภายใต้หัวข้อ **Capacity settings** แล้วเลือก **Data Engineering/Science Settings**

![Screenshot of the Spark settings page in Microsoft Fabric.](https://learn.microsoft.com/en-us/training/wwl/use-apache-spark-work-files-lakehouse/media/spark-settings.png)

การตั้งค่าที่สามารถกำหนดได้สำหรับ _Spark pool_ ได้แก่:

- **_Node Family_**: ประเภทของเครื่องเสมือน (_virtual machines_) ที่ใช้ใน _Spark cluster_ โดยส่วนใหญ่จะเลือกเป็น _memory optimized_ เพื่อให้ได้ _performance_ ที่ดีที่สุด
- **_Autoscale_**: เปิดหรือไม่เปิดการปรับจำนวน _nodes_ อัตโนมัติ หากเปิด จะสามารถกำหนดจำนวน _initial nodes_ และ _maximum nodes_ ได้
- **_Dynamic allocation_**: เปิดหรือไม่ให้ระบบจัดสรร _executor processes_ บน _worker nodes_ แบบอัตโนมัติตามปริมาณข้อมูล

หากคุณสร้าง _custom Spark pool_ ขึ้นใน _workspace_ หลายอัน คุณสามารถกำหนดให้หนึ่งในนั้น (หรือ _starter pool_) เป็นค่าเริ่มต้น (_default_) สำหรับใช้รัน _Spark job_ ในกรณีที่ไม่ได้ระบุ _pool_ เฉพาะไว้

_เคล็ดลับ_:  
ดูข้อมูลเพิ่มเติมได้ที่ [Configuring starter pools in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-engineering/configure-starter-pools)  และ [How to create custom Spark pools in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-engineering/create-custom-spark-pools)

## Runtimes and environments

ในระบบ _Spark_ แบบ _open source_ มีหลายเวอร์ชันของ _runtime_ ซึ่งจะกำหนดว่าเวอร์ชันของ _Apache Spark_, _Delta Lake_, _Python_ และซอฟต์แวร์หลักอื่น ๆ ที่ติดตั้งอยู่คือเวอร์ชันใด ภายในแต่ละ _runtime_ ยังสามารถติดตั้ง _code libraries_ ได้หลากหลาย ทั้งสำหรับงานทั่วไป และงานเฉพาะทางบางอย่าง โดยเฉพาะอย่างยิ่งเพราะ _PySpark_ เป็นเครื่องมือหลักที่ใช้กันอย่างแพร่หลาย จึงสามารถใช้ไลบรารีภาษา _Python_ ที่มีอยู่มากมายเพื่อรองรับทุกงานที่ต้องการได้

ในบางกรณี องค์กรอาจต้องกำหนด _environments_ หลายชุด เพื่อรองรับลักษณะของงานที่หลากหลาย โดยแต่ละ _environment_ จะระบุ _runtime version_ ที่ต้องใช้ และรายชื่อ _libraries_ ที่ต้องติดตั้งสำหรับงานเฉพาะทางนั้น

จากนั้น _data engineer_ และ _data scientist_ สามารถเลือก _environment_ ที่ต้องการใช้กับ _Spark pool_ ตามแต่ละงานได้อย่างยืดหยุ่น

### Spark runtimes in Microsoft Fabric

_Microsoft Fabric_ รองรับหลายเวอร์ชันของ _Spark runtime_ และจะมีการอัปเดตเพื่อรองรับเวอร์ชันใหม่ ๆ เพิ่มเติมในอนาคต

คุณสามารถใช้เมนู _workspace settings_ เพื่อกำหนดว่า _default environment_ ควรใช้ _Spark runtime_ เวอร์ชันใด เมื่อมีการเริ่มต้น _Spark pool_

_เคล็ดลับ_:  
ดูข้อมูลเพิ่มเติมเกี่ยวกับ _Spark runtimes_ ใน _Microsoft Fabric_ ได้ที่ [Apache Spark Runtimes in Fabric](https://learn.microsoft.com/en-us/fabric/data-engineering/runtime)

### Environments in Microsoft Fabric

คุณสามารถสร้าง _custom environments_ ภายใน _Fabric workspace_ ได้ เพื่อให้สามารถกำหนด _Spark runtime_, ไลบรารี (_libraries_) และการตั้งค่าเฉพาะ (_configuration settings_) สำหรับแต่ละงานประมวลผลข้อมูล (_data processing operations_) ได้อย่างยืดหยุ่น

![Screenshot of the Environment page in Microsoft Fabric.](https://learn.microsoft.com/en-us/training/wwl/use-apache-spark-work-files-lakehouse/media/spark-environment.png)

เมื่อสร้าง _environment_ ใหม่ คุณสามารถ:

- ระบุว่าจะใช้ _Spark runtime_ เวอร์ชันใด
- ดูรายการ _built-in libraries_ ที่ติดตั้งในทุก _environment_
- ติดตั้งไลบรารีจาก _Python Package Index (PyPI)_
- ติดตั้งไลบรารีเฉพาะทางโดยการอัปโหลดไฟล์แพ็กเกจ
- ระบุว่า _environment_ นี้จะใช้ _Spark pool_ ใด
- กำหนดค่าคอนฟิกของ _Spark_ เพื่อเปลี่ยนพฤติกรรมจากค่าปริยาย
- อัปโหลดไฟล์ทรัพยากร (_resource files_) ที่ต้องใช้งานภายใน _environment_

หลังจากสร้าง _custom environment_ อย่างน้อย 1 อันแล้ว คุณสามารถตั้งให้ _environment_ นั้นเป็นค่าเริ่มต้น (_default_) ได้ใน _workspace settings_

_เคล็ดลับ_:  
ดูข้อมูลเพิ่มเติมได้ที่ [Create, configure, and use an environment in Microsoft Fabric](https://learn.microsoft.com/en-us/fabric/data-engineering/create-and-use-environment)

## Additional Spark configuration options

การจัดการ _Spark pools_ และ _environments_ เป็นวิธีหลักในการควบคุมการประมวลผลด้วย _Spark_ ภายใน _Fabric workspace_ อย่างไรก็ตาม ยังมีตัวเลือกเพิ่มเติมบางอย่างที่สามารถใช้เพื่อเพิ่มประสิทธิภาพ (_optimization_) ได้มากยิ่งขึ้น

### Native execution engine

_native execution engine_ ใน _Microsoft Fabric_ คือเอนจินประมวลผลแบบ _vectorized_ ซึ่งสามารถรัน _Spark operations_ ได้โดยตรงบนโครงสร้างของ _lakehouse_

การใช้ _native execution engine_ จะช่วยเพิ่ม _performance_ ของการรันคำสั่ง _query_ ได้อย่างมาก โดยเฉพาะเมื่อทำงานกับข้อมูลขนาดใหญ่ในรูปแบบไฟล์ _Parquet_ หรือ _Delta_

หากต้องการเปิดใช้งาน _native execution engine_ สามารถทำได้ในระดับ _environment_ โดยตั้งค่า _Spark properties_ ดังนี้ใน _environment configuration_:

- `spark.native.enabled`: `true`  
- `spark.shuffle.manager`: `org.apache.spark.shuffle.sort.ColumnarShuffleManager`

ในการเปิดใช้งาน _native execution engine_ สำหรับสคริปต์หรือ _notebook_ เฉพาะ คุณสามารถตั้งค่าดังนี้ที่จุดเริ่มต้นของโค้ด:

```json
%%configure 
{ 
   "conf": {
       "spark.native.enabled": "true", 
       "spark.shuffle.manager": "org.apache.spark.shuffle.sort.ColumnarShuffleManager" 
   } 
}
```

_Tip_: ดูรายละเอียดเพิ่มเติมเกี่ยวกับ _native execution engine_ ได้ที่ [**Native execution engine for Fabric Spark**](https://learn.microsoft.com/en-us/fabric/data-engineering/native-execution-engine-overview)

### High concurrency mode

เมื่อคุณรันโค้ด _Spark_ ใน Microsoft Fabric ระบบจะเริ่มต้น _Spark session_ ขึ้นมาโดยอัตโนมัติ ซึ่งสามารถเพิ่มประสิทธิภาพในการใช้งานทรัพยากรได้โดยการเปิดใช้งาน _high concurrency mode_

_high concurrency mode_ ช่วยให้ _Spark session_ สามารถถูกใช้งานร่วมกันได้ระหว่างผู้ใช้หรือโปรเซสหลายรายในเวลาเดียวกัน โดยยังคง _isolated execution_ คือ _notebook_ แต่ละอันยังแยกกันทำงาน ไม่โดนรบกวนจากตัวแปรหรือโค้ดของกันและกัน

เมื่อเปิดใช้งานโหมดนี้:
- ผู้ใช้หลายคนสามารถรัน _notebooks_ ที่ใช้ _Spark session_ ร่วมกันได้
- _Spark jobs_ ที่ไม่โต้ตอบ (_non-interactive scripts_) ก็สามารถรันพร้อมกันได้อย่างมีประสิทธิภาพมากขึ้นเช่นกัน

สามารถเปิด _high concurrency mode_ ได้จากหน้าตั้งค่าในส่วน **Data Engineering/Science** ของ _workspace_

_Tip_: ดูข้อมูลเพิ่มเติมเกี่ยวกับ _high concurrency mode_ ได้ที่ [**High concurrency mode in Apache Spark for Fabric**](https://learn.microsoft.com/en-us/fabric/data-engineering/high-concurrency-overview)

### Automatic MLFlow logging

_MLFlow_ เป็นไลบรารีแบบ _open source_ ที่ใช้ในงานด้าน _data science_ เพื่อจัดการการฝึกโมเดลและการนำโมเดลไปใช้งาน (_deployment_) โดยมีความสามารถสำคัญคือการ _log_ ข้อมูลต่าง ๆ ระหว่างฝึกโมเดลและจัดการโมเดล

ใน Microsoft Fabric ระบบจะใช้ _MLFlow_ ในการบันทึกกิจกรรมของการทดลองโมเดล (_experiment activity_) โดยอัตโนมัติ (_implicit logging_) โดยที่ _data scientist_ ไม่จำเป็นต้องเขียนโค้ดเพื่อ _log_ เอง

ถ้าต้องการปิดความสามารถนี้ สามารถทำได้ในหน้าตั้งค่าของ _workspace_

### Spark administration for a Fabric capacity

ผู้ดูแลระบบ (_administrators_) สามารถจัดการการตั้งค่า _Spark_ ได้ในระดับ _Fabric capacity_ ซึ่งช่วยให้สามารถ _จำกัด_ หรือ _บังคับใช้_ การตั้งค่าบางอย่างของ _Spark_ กับทุก _workspace_ ภายในองค์กรได้

ตัวอย่างเช่น องค์กรอาจกำหนดให้ใช้ _high concurrency mode_ เป็นค่าเริ่มต้น หรือปิดการ _log_ อัตโนมัติของ _MLFlow_ สำหรับทุกผู้ใช้ในทุกโปรเจกต์

_Tip_: อ่านเพิ่มเติมเกี่ยวกับการจัดการการตั้งค่าสำหรับ _data engineering_ และ _data science_ ในระดับ _Fabric capacity_ ได้ที่ [**Configure and manage data engineering and data science settings for Fabric capacities**](https://learn.microsoft.com/en-us/fabric/data-engineering/capacity-settings-management?azure-portal-true)
