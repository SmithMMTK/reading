
มีหลายวิธีในการวัด _คุณภาพของคำตอบ_ จากระบบ _generative AI_ โดยทั่วไปสามารถแบ่งออกเป็น 3 มิติหลักในการประเมิน ได้แก่

- _Performance and quality evaluators_: ใช้ประเมินด้าน _ความถูกต้อง (accuracy)_, การอ้างอิงกับข้อมูลจริง (groundedness), และ _ความเกี่ยวข้องของเนื้อหา (relevance)_
- _Risk and safety evaluators_: ใช้ตรวจสอบ _ความเสี่ยง_ ที่อาจเกิดจากคำตอบ เช่น เนื้อหาที่เป็นอันตราย ไม่เหมาะสม หรืออาจก่อให้เกิดความเข้าใจผิด
- _Custom evaluators_: ตัววัดที่ออกแบบเฉพาะสำหรับอุตสาหกรรมหรือวัตถุประสงค์เฉพาะด้าน

Azure AI Foundry มีฟีเจอร์ด้าน _observability_ เพื่อช่วยติดตามและประเมิน _คุณภาพและความน่าเชื่อถือ_ ของคำตอบที่โมเดลสร้างขึ้น โดยใช้ _evaluators_ ซึ่งเป็นเครื่องมือเฉพาะทาง เช่น

- _Groundedness_: วัดว่าเนื้อหาตอบสนองสอดคล้องกับ _ข้อมูลอ้างอิง_ ที่ดึงมาได้แค่ไหน
- _Relevance_: วัดว่าเนื้อหาสอดคล้องกับคำถามหรือไม่
- _Fluency_: วัดว่าเนื้อหานั้นอ่านเข้าใจง่าย มีความเป็น _ภาษาธรรมชาติ_
- _Coherence_: วัดว่าเนื้อหามี _ความลื่นไหล_ และ _เชื่อมโยงกันได้อย่างมีเหตุผล_
- _Content safety_: ประเมินความปลอดภัยของเนื้อหาจากหลายมุม เช่น ความรุนแรง ความลำเอียง หรือข้อมูลที่ผิด

ต่อไปลองใช้งาน _ความสามารถของ generative AI_ ใน Azure AI Foundry portal กัน

