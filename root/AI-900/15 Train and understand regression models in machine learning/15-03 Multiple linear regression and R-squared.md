
ในยูนิตนี้ เราจะเปรียบเทียบระหว่าง _multiple linear regression_ กับ _simple linear regression_ รวมถึงเรียนรู้เกี่ยวกับ _ตัวชี้วัด_ ที่เรียกว่า _R²_ ซึ่งเป็น _performance metric_ ที่ใช้กันอย่างแพร่หลายในการประเมินคุณภาพของโมเดล _linear regression_

## Multiple linear regression

_Multiple linear regression_ เป็นการสร้างโมเดลที่เชื่อมโยงระหว่าง _features หลายตัว_ กับ _label หนึ่งตัว_ โดยในทางคณิตศาสตร์จะคล้ายกับ _simple linear regression_ และมักใช้ _cost function_ แบบเดียวกัน ต่างกันเพียงแค่มี _features_ มากกว่า

แทนที่จะสร้างความสัมพันธ์เดียว เทคนิคนี้จะ _สร้างหลายความสัมพันธ์ในเวลาเดียวกัน_ และถือว่าแต่ละความสัมพันธ์นั้น _เป็นอิสระจากกัน_ เช่น หากเราต้องการทำนายว่า _สุนัขจะป่วยมากน้อยแค่ไหน_ โดยพิจารณาจากทั้ง _อายุ_ (_age_) และ _เปอร์เซ็นต์ไขมันในร่างกาย_ (_body_fat_percentage_) เราจะได้ 2 ความสัมพันธ์:

- อายุมีผลต่อระดับความป่วยมากน้อยแค่ไหน
- เปอร์เซ็นต์ไขมันมีผลต่อความป่วยมากน้อยแค่ไหน

ถ้าเราทำงานกับ _2 features_ เราสามารถ _วาดภาพโมเดล_ ได้เหมือน _พื้นผิวระนาบ (plane)_ ใน 2 มิติ แทนที่จะเป็นเส้นตรงเหมือนใน _simple linear regression_ เราจะได้เห็นภาพนี้ในแบบฝึกหัดถัดไป

### Multiple linear regression has assumptions

สิ่งที่โมเดล _multiple linear regression_ คาดหวังว่า _features จะต้องเป็นอิสระต่อกัน_ (_independent_) นั้น เรียกว่าเป็น _model assumption_ ซึ่งถ้า _สมมติฐานนี้ไม่เป็นจริง_ โมเดลอาจให้ผลลัพธ์ที่ _ทำให้เข้าใจผิด_ ได้

ตัวอย่างเช่น อายุอาจเป็นตัวทำนายความป่วยของสุนัขได้ดี เพราะ _สุนัขที่อายุมากมักจะป่วยง่าย_ และยังเกี่ยวข้องกับการที่สุนัขรู้จักเล่นฟรีสบี้ด้วย เพราะสุนัขที่อายุมากกว่าส่วนใหญ่ก็มักถูกฝึกให้เล่นฟรีสบี้มาแล้ว

ถ้าเราใส่ทั้ง _age_ และ _knows_frisbee_ ลงไปเป็น _features_ ในโมเดล โมเดลอาจสรุปว่า _การรู้จักเล่นฟรีสบี้_ เป็นตัวทำนายโรคได้ดี และลดความสำคัญของอายุลง ซึ่งดูจะ _ไม่สมเหตุสมผล_ เพราะการเล่นฟรีสบี้ไม่น่าจะทำให้เกิดโรค

ในทางกลับกัน _dog_breed_ อาจเป็น _feature_ ที่ช่วยทำนายโรคได้เช่นกัน และเนื่องจาก _age_ กับ _dog_breed_ ไม่มีเหตุผลที่จะสัมพันธ์กันโดยตรง จึงสามารถใส่ทั้งสองตัวนี้ในโมเดลได้อย่าง _ปลอดภัย_

## Goodness of fit: R2

เรารู้ว่า _cost function_ สามารถใช้วัดว่าโมเดล _fit กับข้อมูลที่ฝึก_ ได้ดีแค่ไหน สำหรับ _linear regression_ จะมีตัวชี้วัดพิเศษที่เรียกว่า _R²_ (_R-squared_) ซึ่งมีค่าอยู่ระหว่าง _0 ถึง 1_ และใช้เพื่อบอกว่าโมเดล _linear regression_ นั้น _อธิบายความสัมพันธ์ในข้อมูลได้ดีแค่ไหน_

เวลาที่คนบอกว่า “ความสัมพันธ์แน่นแฟ้น” มักหมายถึง _ค่า R² มีค่าสูง_

แม้ว่า R² จะอาศัยคณิตศาสตร์ที่ลึกเกินกว่าขอบเขตของบทเรียนนี้ แต่เราสามารถเข้าใจแบบง่าย ๆ ได้ เช่น จากแบบฝึกหัดก่อนหน้า ที่เราดูความสัมพันธ์ระหว่าง _age_ กับ _core_temperature_:

- ถ้า _R² = 1_ หมายความว่า เราสามารถใช้ _อายุ_ ทำนายว่า _ตัวไหนจะมีอุณหภูมิสูงหรือต่ำ_ ได้อย่างสมบูรณ์แบบ
- ถ้า _R² = 0_ แปลว่า _ไม่มีความสัมพันธ์ใด ๆ_ ระหว่างอายุกับอุณหภูมิเลย

![Diagram showing a goodness of fit graph with many plot points.](https://learn.microsoft.com/en-us/training/modules/understand-regression-machine-learning/media/4-goodness-of-fit-graph.png)

ความจริงแล้ว ค่า R² มักจะอยู่ _ระหว่าง 0 กับ 1_ เสมอ โมเดลของเราอาจสามารถทำนาย _temperature_ ได้บางระดับ (ดีกว่าการที่ R² = 0) แต่ก็ยังมีข้อมูลหลายจุดที่ _เบี่ยงเบนจากค่าที่โมเดลทำนายไว้_ (แสดงว่า R² ก็ยังน้อยกว่า 1)

แต่ _R² เป็นแค่ครึ่งเดียวของเรื่องทั้งหมด_

แม้ว่า _ค่า R²_ จะเป็นที่ยอมรับอย่างกว้างขวาง แต่ก็ไม่ใช่ตัวชี้วัดที่สามารถใช้แยกเดี่ยวได้เสมอ เพราะมีข้อจำกัดหลายข้อ เช่น:

- เนื่องจากวิธีการคำนวณ _R²_ ทำให้ยิ่งมี _จำนวนข้อมูลมาก_ ค่า R² มักจะยิ่งสูงขึ้น ซึ่งอาจทำให้เราเข้าใจผิดว่าโมเดลหนึ่งดีกว่าอีกโมเดลหนึ่ง ทั้งที่จริง ๆ แล้วอาจเหมือนกัน เพียงแค่ใช้คนละชุดข้อมูล
- ค่า R² _ไม่บอกว่าโมเดลจะทำงานได้ดีกับข้อมูลใหม่_ ที่ไม่เคยเห็นมาก่อน ในสายสถิติจะใช้ _p-value_ มาช่วย แต่ใน _machine learning_ เรามักจะใช้วิธีการ _แยกข้อมูลสำหรับทดสอบ_ โดยเฉพาะ
- ค่า R² _ไม่บอกทิศทางของความสัมพันธ์_ เช่น R² = 0.8 ก็ไม่ได้บอกว่าเส้นโน้มเอียงขึ้นหรือเอียงลง และ _ไม่ได้บอกว่าเส้นชันแค่ไหน_ ด้วย

อีกสิ่งที่ควรจำไว้คือ _ไม่มีเกณฑ์ตายตัวว่า R² เท่าไหร่ถึงจะ “ดีพอ”_

เช่น ในงานวิทยาศาสตร์ฟิสิกส์ ถ้า _R² ไม่ใกล้ 1_ ก็มักจะถือว่าไม่แม่นยำพอ แต่ถ้าเป็นการสร้างโมเดลในระบบที่ซับซ้อน เช่นในชีววิทยาหรือสังคมศาสตร์ _R² เพียง 0.3_ ก็อาจถือว่า _ยอดเยี่ยมแล้ว_

