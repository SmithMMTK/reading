
จากแบบฝึกหัดที่ผ่านมา เราพบว่าโมเดลสามารถทำนายหิมะถล่มได้ในระดับหนึ่ง แต่ยังผิดพลาดอยู่ประมาณ 40% สาเหตุเพราะ _feature_ เดียวที่ใช้คือจำนวน _weak layers_ ของหิมะ ซึ่งไม่ใช่ปัจจัยเดียวที่ส่งผลต่อการเกิดหิมะถล่ม

ต่อไปเราจะลงลึกในสองแนวทางหลักที่ช่วยปรับปรุง _classification_ ให้ดีขึ้น คือการเพิ่ม _features_ และการเลือก _features_ อย่างมีเหตุผล

## Provide more features

เช่นเดียวกับ _linear regression_ โมเดล _logistic regression_ ไม่จำเป็นต้องใช้แค่ _feature_ เดียว เราสามารถรวมหลาย _features_ เพื่อช่วยในการทำนาย เช่น อาจทำนายหิมะถล่มจากปริมาณหิมะที่ตก และจำนวนคนที่เดินบนเส้นทาง โดยป้อนทั้งสอง _features_ นี้เข้าโมเดลเดียวกันเพื่อคำนวณ _probability_ ของการเกิดหิมะถล่ม

ภายในโมเดล _logistic regression_ จะรวม _features_ เข้าด้วยกันในลักษณะเดียวกับ _linear regression_ คือถือว่าแต่ละ _feature_ เป็นอิสระ (_independent_) ซึ่งหมายถึงโมเดลจะไม่คิดว่า _features_ มีผลต่อกัน เช่น โมเดลจะถือว่าปริมาณหิมะที่ตกไม่ส่งผลต่อจำนวนคนที่ไปเดินเขา และโดยค่าเริ่มต้น โมเดลยังถือว่าปริมาณหิมะเพิ่มความเสี่ยงแบบคงที่ ไม่ว่าคนจะเดินมากหรือน้อยแค่ไหน

### The good and bad sides of independent features

แม้ว่าเราสามารถสั่งให้ _logistic regression_ พิจารณาความสัมพันธ์ระหว่าง _features_ ได้โดยตรง แต่โดยปกติแล้วมันจะไม่ทำแบบนั้น ต่างจากอัลกอริธึมจัดกลุ่มอื่น เช่น _decision trees_ หรือ _neural networks_

การที่ _logistic regression_ ถือว่า _features_ เป็นอิสระนั้น มีทั้งข้อดีและข้อเสีย ข้อดีคือโมเดลสามารถให้คำอธิบายที่ชัดเจน เช่น ยิ่งคนเยอะ ยิ่งเสี่ยง ซึ่งโมเดลอื่นอาจไม่สามารถแสดงออกมาได้ง่าย และยังช่วยลดความเสี่ยงในการ _overfitting_ ข้อมูลฝึก

แต่ในโลกความจริง ถ้า _features_ มีปฏิสัมพันธ์กัน โมเดลอาจทำงานได้ไม่ดี เช่น หากมีคนเดินเขา 5 คน บนภูเขาที่มีหิมะ ก็อาจเสี่ยงเกิดหิมะถล่ม แต่ถ้าไม่มีหิมะก็ไม่เสี่ยงเลย โมเดล _logistic regression_ จะไม่สามารถจับความแตกต่างนี้ได้ถ้าไม่ได้บอกให้มันพิจารณาความสัมพันธ์ระหว่างปริมาณหิมะและจำนวนคน

## Think about your features

อีกแนวทางในการปรับปรุงโมเดลคือ การเลือก _features_ อย่างมีเหตุผล โดยทั่วไปยิ่งใส่ _features_ มาก โมเดลจะยิ่งทำงานได้ดีขึ้น **แต่** เงื่อนไขคือ _features_ เหล่านั้นต้องเกี่ยวข้องและให้ข้อมูลใหม่ที่ _features_ อื่นยังไม่ให้

### Avoiding overtraining

ถ้าใส่ _features_ ที่ไม่เกี่ยวข้อง โมเดลอาจเกิด _overtraining_ ทำให้เหมือนว่าทำงานดีขึ้น แต่จริง ๆ แล้วกลับแย่ลงเมื่อนำไปใช้จริง

เช่น ถ้าเรามีข้อมูลรายวันของ _amount_of_snow_, _number_of_hikers_, _temperature_, และ _number_of_birds_spotted_ ซึ่ง "จำนวนนกที่เห็น" ไม่น่าเกี่ยวข้อง แต่ถ้าใส่เข้าไป โมเดลอาจเรียนรู้ว่าหิมะถล่มมักเกิดในวันที่มีนกมาก และนำไปสู่ข้อสรุปผิด ๆ ว่านกทำให้เกิดหิมะถล่ม กลายเป็นวางแผนสังเกตนกเพื่อทำนายหิมะถล่ม ซึ่งสุดท้ายก็ใช้ไม่ได้จริง

### Avoiding undertraining

การใช้ _features_ แบบหยาบเกินไปอาจทำให้โมเดล _undertrain_ เช่น ถ้า _temperature_ กับ _number_of_hikers_ ทั้งสองเกี่ยวข้องกับหิมะถล่ม แต่คนมักเดินป่าเฉพาะวันที่อากาศดี โมเดลจะสับสนและแยกไม่ออกว่าอะไรกันแน่ที่ส่งผลมากกว่า

ในกรณีนี้ เราอาจปรับปรุงโมเดลได้ดีขึ้นหากระบุ _number_of_hikers_ เป็นจำนวนจริง แทนที่จะใช้แค่ “สูง” หรือ “ต่ำ” เพื่อให้โมเดลสามารถเรียนรู้ความสัมพันธ์ได้ละเอียดมากขึ้น
