
ตลอดหลายทศวรรษที่ผ่านมา ได้มีความก้าวหน้าอย่างต่อเนื่องในด้าน _natural language processing (NLP)_ ซึ่งนำไปสู่การพัฒนา _large language models (LLMs)_ ที่ทรงพลัง และเปิดทางให้เกิดวิธีใหม่ ๆ ในการโต้ตอบกับระบบ เช่น _generative AI assistants_ และ _agents_

ลองย้อนดูพัฒนาการสำคัญของ _language models_ ในอดีต:

- _Tokenization_: ทำให้เครื่องสามารถ “อ่าน” ข้อความได้ โดยแยกประโยคออกเป็นหน่วยย่อย เช่น คำ หรือคำย่อย
- _Word embeddings_: ทำให้เครื่องเข้าใจ _ความสัมพันธ์ระหว่างคำ_ เช่น คำที่มีความหมายใกล้กันจะอยู่ใกล้กันในเชิงคณิตศาสตร์
- _Architectural developments_: การพัฒนา _โครงสร้างของโมเดล_ เช่น RNN, LSTM, Transformer ทำให้โมเดลสามารถ _เข้าใจบริบทของคำ_ ได้ดีขึ้น


## Tokenization

อย่างที่คาดไว้ เครื่องไม่สามารถเข้าใจข้อความโดยตรงได้ดีนัก เพราะเครื่องส่วนใหญ่ทำงานโดยอิงจาก _ตัวเลข_ ดังนั้นเพื่อให้เครื่องสามารถ “อ่าน” ข้อความได้ เราจึงต้อง _แปลงข้อความให้กลายเป็นตัวเลข_

หนึ่งในการพัฒนาที่สำคัญคือกระบวนการที่เรียกว่า _tokenization_  
_token_ คือชุดข้อความขนาดสั้นที่มีความหมายในตัวเอง มักจะแทนคำหนึ่งคำหรือบางส่วนของคำ

ขั้นตอน _tokenization_ คือการแปลงคำให้กลายเป็น _tokens_ แล้วแปลง tokens เหล่านั้นเป็นตัวเลข เพื่อให้เครื่องนำไปประมวลผลได้

วิธีการเชิงสถิติหนึ่งที่ใช้ใน _tokenization_ คือการใช้ _pipeline_ ที่มีขั้นตอนต่อเนื่องในการแยกคำ แปลงคำ และแมปกับตัวเลข

![A screenshot showing the pipeline of tokenization of a sentence.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-generative-ai/media/tokenization-pipeline.png)

ขั้นตอนของ _tokenization_ แบบง่ายสามารถอธิบายได้ดังนี้:

1. เริ่มจากข้อความที่ต้องการแปลงเป็น token
2. แยกคำในข้อความโดยอิงตามกฎ เช่น แยกเมื่อเจอช่องว่าง (space)
3. _Stop word removal_: ลบคำที่ไม่มีความหมายเชิงเนื้อหา เช่น _the_, _and_, _a_ โดยอ้างอิงจาก _dictionary_ ของคำเหล่านี้เพื่อกรองออก
4. กำหนดหมายเลขให้กับแต่ละ _token_ ที่ไม่ซ้ำกัน เพื่อใช้แทน token นั้นในรูปแบบตัวเลข

การมี _tokenization_ ทำให้สามารถ _ติดป้ายกำกับ (label)_ ให้กับข้อความได้

ผลที่ตามมาคือ เราสามารถนำเทคนิคทางสถิติมาใช้กับข้อมูลข้อความ เพื่อให้คอมพิวเตอร์ _ค้นหารูปแบบ (patterns)_ จากข้อมูลด้วยตัวเอง แทนที่จะต้องใช้กฎที่มนุษย์กำหนดไว้ล่วงหน้าแบบ _rule-based models_

## Word embeddings

หนึ่งในแนวคิดสำคัญที่เกิดขึ้นเมื่อมีการนำ _deep learning_ มาใช้กับ _NLP_ คือ _word embeddings_ ซึ่งช่วยแก้ปัญหาการไม่สามารถอธิบาย _ความสัมพันธ์เชิงความหมาย (semantic relationship)_ ระหว่างคำต่าง ๆ ได้

_word embeddings_ ถูกสร้างขึ้นระหว่างขั้นตอน _training_ ของโมเดล deep learning โดยโมเดลจะวิเคราะห์รูปแบบการเกิดร่วมกันของคำในประโยค และเรียนรู้ที่จะแปลงคำเหล่านั้นให้เป็น _vectors_ หรือเส้นทางใน _n-dimensional space_ (พื้นที่หลายมิติ)

ความสัมพันธ์เชิงความหมายระหว่างคำจะสะท้อนผ่าน _ทิศทางของเวกเตอร์_ หากคำสองคำมีทิศทางของเวกเตอร์ใกล้กัน แสดงว่ามีความหมายใกล้เคียงกัน

เพื่อสร้าง _vocabulary_ ที่มีความสัมพันธ์เชิงความหมายระหว่าง _tokens_ เราจะกำหนด _contextual vectors_ ให้กับแต่ละ token ซึ่งเรียกว่า _embeddings_

เวกเตอร์เหล่านี้เป็นชุดตัวเลขหลายค่า เช่น [10, 3, 1] โดยแต่ละค่าจะแทน _ลักษณะเชิงความหมายบางอย่าง_ ของ token นั้น โดยโมเดลจะเรียนรู้ว่าควรกำหนดค่าอย่างไรจากบริบทและความถี่ของการเกิดร่วมกันของคำระหว่างการฝึก

เวกเตอร์แสดงถึงเส้นใน _multidimensional space_ โดยอธิบายทั้ง _ทิศทาง (amplitude)_ และ _ระยะทาง (magnitude)_ ของเส้นนั้นจากจุดเริ่มต้นถึงจุดปลาย สรุปแล้วเวกเตอร์คือการอธิบาย _ทิศทางและความห่างเชิงความหมาย_ ของคำในมุมมองเชิงคณิตศาสตร์

![A screenshot showing a simple example of word embeddings.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-generative-ai/media/word-embeddings.png)

แต่ละองค์ประกอบในเวกเตอร์ของ _token_ ใน _embedding space_ จะแทน _ลักษณะเชิงความหมาย_ ของคำนั้น ๆ ดังนั้นหาก _tokens_ มีความหมายใกล้เคียงกัน เวกเตอร์ของมันก็ควรจะ _ชี้ไปในทิศทางที่ใกล้กัน_

เราสามารถใช้เทคนิคที่เรียกว่า _cosine similarity_ เพื่อตรวจสอบว่าเวกเตอร์สองตัวมีทิศทางใกล้เคียงกันหรือไม่ (โดยไม่สนใจเรื่องระยะทาง) ซึ่งช่วยให้เราระบุได้ว่าคำสองคำมีความหมายเชื่อมโยงกันหรือเปล่า

ตัวอย่างเช่น เวกเตอร์ของคำว่า _"dog"_ และ _"puppy"_ จะชี้ไปในทิศทางเกือบเหมือนกัน และยังใกล้เคียงกับคำว่า _"cat"_ ด้วย ขณะที่เวกเตอร์ของคำว่า _"skateboard"_ จะชี้ไปคนละทางอย่างชัดเจน แสดงว่ามี _ความหมายที่ต่างกันอย่างมาก_

## Architectural developments

สถาปัตยกรรม (_architecture_) หรือโครงสร้างของโมเดล _machine learning_ คือการออกแบบระบบและองค์ประกอบต่าง ๆ ของโมเดล ซึ่งกำหนดว่า _ข้อมูลจะถูกประมวลผลอย่างไร_ โมเดลจะ _ฝึกและประเมินผลอย่างไร_ และจะ _สร้างผลลัพธ์การทำนาย_ ได้อย่างไร

หนึ่งในความก้าวหน้าครั้งแรกของ _language model architecture_ คือ _Recurrent Neural Networks (RNNs)_

การเข้าใจข้อความไม่ใช่แค่การเข้าใจคำทีละคำแบบโดด ๆ เพราะ _ความหมายของคำขึ้นอยู่กับบริบทที่มันอยู่_ กล่าวคือ _คำรอบ ๆ_  มีผลต่อความหมายของคำ

_RNN_ สามารถเข้าใจบริบทของคำได้ด้วยกระบวนการแบบลำดับ (sequential) โดยในแต่ละขั้นจะรับ _input_ (เช่น คำใหม่ในประโยค) และ _hidden state_ ซึ่งทำหน้าที่เป็นหน่วยความจำที่ส่งต่อข้อมูลจากขั้นก่อนหน้าไปยังขั้นถัดไป

ตัวอย่างเช่น ประโยค:

Vincent Van Gogh was a painter most known for creating stunning and emotionally expressive artworks, including ...

เพื่อทำนายคำถัดไป เราต้อง _จดจำชื่อของศิลปิน_ ที่ถูกกล่าวถึง เพื่อให้เติมประโยคให้สมบูรณ์

ในงาน NLP หากมีคำหายไป เรามักใช้ token พิเศษ _[MASK]_ เพื่อบอกโมเดลให้ _ทำนายคำที่หายไป_

ถ้าเราย่อประโยคข้างต้นให้สั้นลง เราอาจให้ _input_ กับ RNN ดังนี้:

Vincent was a painter known for [MASK]

![Diagram showing the sentence tokenized to present the most important words in a sentence as individual tokens.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-generative-ai/media/vincent-tokenized.png)

_RNN_ จะรับ _token_ ทีละตัวเป็น _input_ จากนั้นประมวลผลและอัปเดต _hidden state_ เพื่อเก็บ “ความทรงจำ” ของ token นั้นไว้

เมื่อรับ token ถัดไป โมเดลจะนำ _hidden state_ จากขั้นก่อนหน้ามาใช้งาน และอัปเดตใหม่ให้สะท้อนบริบทล่าสุดของประโยค

สุดท้าย โมเดลจะได้รับ _token_ พิเศษคือ _[MASK]_ เป็น input ซึ่งบอกว่า “มีคำหายไป” และโมเดลต้อง _ทำนายค่าที่หายไป_

_RNN_ จะใช้ข้อมูลทั้งหมดที่จำไว้ใน _hidden state_ เพื่อทำนายคำที่เหมาะสม เช่นคำว่า _Starry Night_  
(ซึ่งเป็นผลงานชื่อดังของ Van Gogh)

![Diagram showing a recurrent network with multiple steps. Each step takes an input and hidden state as input and produces an output.](https://learn.microsoft.com/en-us/training/wwl-data-ai/fundamentals-generative-ai/media/recurrent-network.gif)

#### Challenges with RNNs

ในตัวอย่างที่กล่าวถึง _hidden state_ ของ RNN จะเก็บข้อมูลของคำว่า Vincent, is, painter, และ know เอาไว้ โดยใน _RNN_ แต่ละ token ที่ผ่านมาจะมีความสำคัญเท่า ๆ กันเมื่อใช้ในการทำนายคำที่หายไป

_RNN_ ทำให้โมเดลสามารถพิจารณา _บริบท (context)_ เพื่อทำความเข้าใจความหมายของคำในประโยคได้  
แต่เนื่องจาก _hidden state_ ถูกอัปเดตในทุกขั้นตอน ข้อมูลที่สำคัญจริง ๆ อาจ _ถูกลบหรือเจือจางไป_ เมื่อมี token ใหม่เข้ามา

ในตัวอย่างที่ให้มา ชื่อ "Vincent Van Gogh" ปรากฏตั้งแต่ต้นประโยค แต่คำ _[MASK]_ อยู่ท้ายประโยค  
เมื่อถึงขั้นตอนสุดท้ายที่ต้องทำนาย [MASK] โมเดลอาจมี _hidden state_ ที่เต็มไปด้วยข้อมูลอื่น ๆ ที่ไม่เกี่ยวข้อง ซึ่งอาจทำให้ _ข้อมูลที่เกี่ยวข้องจริง ๆ_ ถูกมองข้ามไป

เพราะ _hidden state_ มีขนาดจำกัด โมเดลอาจต้อง “ลบ” ข้อมูลเก่าออก เพื่อเก็บข้อมูลใหม่ ทำให้ข้อมูลสำคัญกลายเป็น _สัญญาณที่อ่อนลง_ ในการทำนาย

ในฐานะมนุษย์ เรารู้ว่าคำบางคำมีน้ำหนักมากกว่าคำอื่นในการทำนาย แต่ RNN จะรวมทุกคำไว้เท่า ๆ กันใน hidden state

จนถึงตรงนี้ เราได้อธิบายว่า _language model_ สามารถอ่านข้อความผ่าน _tokenization_ เข้าใจ _ความสัมพันธ์ระหว่างคำ_ ผ่าน _word embeddings_ และพยายามเข้าใจบริบทผ่าน RNN อย่างไร

ต่อไป เราจะเรียนรู้ว่า _ข้อจำกัดของโมเดลในอดีต_ ถูกแก้ไขอย่างไรในโมเดลสมัยใหม่ ด้วย _transformer architecture_

